Neural network model definition file
===

A description of the model. You must not use &num; and &dollar; characters.
If you need these characters, type `&num;` and `&dollar;` instead.


UUID
---

A unique identifier of this model definition file.

```
uuid: 1dd4ae48-aca8-4882-98ee-8a846a66e176
```

Statistics
---

Training and validation statistics.

```
{
  "class:training:residuals:mean": -0.0007408200890455394,
  "class:training:residuals:std": 0.3672624121827297,
  "class:training:residuals:max": 4.983485221862793,
  "class:training:residuals:mean:1": 0.08354731497840336,
  "class:training:residuals:std:1": 0.24434485686212312,
  "class:training:residuals:max:1": 4.983485221862793,
  "class:training:residuals:mean:2": 0.11352081974873585,
  "class:training:residuals:std:2": 0.24459558862927383,
  "class:training:residuals:max:2": 2.9794859886169434,
  "class:training:residuals:mean:3": -0.0060718216917597665,
  "class:training:residuals:std:3": 0.5510187365738772,
  "class:training:residuals:max:3": 2.9919800758361816,
  "class:training:residuals:mean:4": -0.009900018803345671,
  "class:training:residuals:std:4": 0.5257100186663157,
  "class:training:residuals:max:4": 1.993171215057373,
  "class:training:residuals:mean:5": -0.059082735468219696,
  "class:training:residuals:std:5": 0.24058472360727368,
  "class:training:residuals:max:5": 3.980749726295471,
  "class:training:residuals:mean:6": -0.11081569581240883,
  "class:training:residuals:std:6": 0.34647161342027066,
  "class:training:residuals:max:6": 4.983235836029053
}
```

JSON
---

A representation of the model in JSON. To save (or load) a model to (or from) a JSON configuration, use:

```
config = model.to_json()
model = tf.keras.models.model_from_json(config)
```

The configuration of this model is:

```
{
  "class_name": "Sequential",
  "config": {
    "name": "sequential",
    "layers": [
      {
        "class_name": "InputLayer",
        "config": {
          "batch_input_shape": [
            null,
            21
          ],
          "dtype": "float32",
          "sparse": false,
          "ragged": false,
          "name": "inputs"
        }
      },
      {
        "class_name": "LognormalNoise",
        "config": {
          "name": "lognormal_noise",
          "trainable": true,
          "dtype": "float32",
          "std": 0.0035360678925035363,
          "seed": null
        }
      },
      {
        "class_name": "UnitRescaling",
        "config": {
          "n": 21,
          "a": [
            [
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ]
          ],
          "b": [
            [
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0,
              1.0
            ]
          ],
          "signed": false,
          "invert": false,
          "name": "02_unit_rescaling"
        }
      },
      {
        "class_name": "Dense",
        "config": {
          "name": "03_dense",
          "trainable": true,
          "dtype": "float32",
          "units": 42,
          "activation": "sigmoid",
          "use_bias": true,
          "kernel_initializer": {
            "class_name": "GlorotNormal",
            "config": {
              "seed": null
            }
          },
          "bias_initializer": {
            "class_name": "Zeros",
            "config": {}
          },
          "kernel_regularizer": {
            "class_name": "OrthogonalRegularizer",
            "config": {
              "factor": 0.009999999776482582,
              "mode": "rows"
            }
          },
          "bias_regularizer": null,
          "activity_regularizer": null,
          "kernel_constraint": null,
          "bias_constraint": null
        }
      },
      {
        "class_name": "Dense",
        "config": {
          "name": "04_dense",
          "trainable": true,
          "dtype": "float32",
          "units": 8,
          "activation": "sigmoid",
          "use_bias": true,
          "kernel_initializer": {
            "class_name": "GlorotNormal",
            "config": {
              "seed": null
            }
          },
          "bias_initializer": {
            "class_name": "Zeros",
            "config": {}
          },
          "kernel_regularizer": {
            "class_name": "OrthogonalRegularizer",
            "config": {
              "factor": 0.009999999776482582,
              "mode": "rows"
            }
          },
          "bias_regularizer": null,
          "activity_regularizer": null,
          "kernel_constraint": null,
          "bias_constraint": null
        }
      },
      {
        "class_name": "Dense",
        "config": {
          "name": "05_dense",
          "trainable": true,
          "dtype": "float32",
          "units": 4,
          "activation": "sigmoid",
          "use_bias": true,
          "kernel_initializer": {
            "class_name": "GlorotNormal",
            "config": {
              "seed": null
            }
          },
          "bias_initializer": {
            "class_name": "Zeros",
            "config": {}
          },
          "kernel_regularizer": {
            "class_name": "OrthogonalRegularizer",
            "config": {
              "factor": 0.009999999776482582,
              "mode": "rows"
            }
          },
          "bias_regularizer": null,
          "activity_regularizer": null,
          "kernel_constraint": null,
          "bias_constraint": null
        }
      },
      {
        "class_name": "Dense",
        "config": {
          "name": "06_dense",
          "trainable": true,
          "dtype": "float32",
          "units": 2,
          "activation": "sigmoid",
          "use_bias": true,
          "kernel_initializer": {
            "class_name": "GlorotNormal",
            "config": {
              "seed": null
            }
          },
          "bias_initializer": {
            "class_name": "Zeros",
            "config": {}
          },
          "kernel_regularizer": {
            "class_name": "OrthogonalRegularizer",
            "config": {
              "factor": 0.009999999776482582,
              "mode": "rows"
            }
          },
          "bias_regularizer": null,
          "activity_regularizer": null,
          "kernel_constraint": null,
          "bias_constraint": null
        }
      },
      {
        "class_name": "Dense",
        "config": {
          "name": "07_dense",
          "trainable": true,
          "dtype": "float32",
          "units": 1,
          "activation": "sigmoid",
          "use_bias": true,
          "kernel_initializer": {
            "class_name": "GlorotNormal",
            "config": {
              "seed": null
            }
          },
          "bias_initializer": {
            "class_name": "Zeros",
            "config": {}
          },
          "kernel_regularizer": {
            "class_name": "OrthogonalRegularizer",
            "config": {
              "factor": 0.009999999776482582,
              "mode": "rows"
            }
          },
          "bias_regularizer": null,
          "activity_regularizer": null,
          "kernel_constraint": null,
          "bias_constraint": null
        }
      },
      {
        "class_name": "UnitRescaling",
        "config": {
          "n": 1,
          "a": [
            [
              1.0
            ]
          ],
          "b": [
            [
              6.0
            ]
          ],
          "signed": false,
          "invert": true,
          "name": "08_unit_rescaling"
        }
      }
    ]
  },
  "keras_version": "2.10.0",
  "backend": "tensorflow"
} 
```

SNNS
---

A representation of the model in custom Stuttgart Neural Network (SNN) Simulator format.

Helmut Schiller (deceased) used a streamlined SNN-based model for his feed-forward back-propagation (FFBP) neural network software. He developed a custom file format for storing his models, too, which is different from the original SNN format. We yet use the term SNN to refer to FFBP neural networks and file format because all artificial neural networks use feed-forwarding and back-propagation and, thus, these terms are not distinctive.

```
#
21
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
0.0 1.0
1
1.0 6.0
$
#planes=6 21 42 8 4 2 1 
bias 1 42
-6.2796855
2.1310103
-0.6965132
-3.695512
6.125372
-0.42322403
8.25704
3.974353
5.0688343
-4.439092
-1.7637373
6.049969
0.29122317
-7.451938
6.119713
-2.0984516
2.2604969
-2.4136736
3.090672
1.8259424
2.2022178
-3.5298514
0.33298936
-0.9187632
1.9362649
-5.0273905
2.4229233
-0.07926386
-2.3501883
0.40044883
1.0325415
-4.197675
-0.72253305
3.6149218
1.8895278
-1.8910227
7.7122865
0.06953313
-6.605644
2.0697894
-2.7596586
-3.9572241
bias 2 8
0.6826059
0.61442065
-0.3926759
0.51841897
-1.0754169
-0.30771223
-0.19917783
0.4011649
bias 3 4
0.5806895
0.65494126
3.3328812
0.7961039
bias 4 2
2.1276336
-2.0908465
bias 5 1
-5.69461
wgt 0 21 42
5.952255
8.941204
10.515173
-5.0671535
-4.9577694
-1.6302989
2.8217475
-2.353258
-1.4574485
-0.59970516
3.3019257
-0.6609316
7.7561817
6.204236
1.9553901
3.4199648
0.52596277
-15.158717
-11.828328
0.6771846
10.426137
1.8558397
-2.5226283
-4.517235
-8.731397
-5.346939
-0.39601597
-1.1962054
1.0916338
1.2744247
0.77809244
-3.5328536
-1.679096
1.8874295
6.7225614
1.2446581
-2.5313478
-0.52097946
-1.158083
2.6409855
-3.1400144
9.545802
2.5807421
2.5325058
1.0821917
0.44916084
1.834437
-7.327038
-10.073648
-3.8603735
-1.2497388
-0.3448629
-4.2005525
-2.4988697
0.3389682
-1.4063777
-2.508617
0.3232551
2.7136993
8.769476
-2.3176472
2.775032
7.36923
5.0305133
4.856845
3.1103287
2.11966
2.2370033
0.0368147
0.19524524
-2.3988416
-2.0280747
-2.5411198
-1.1949129
3.9798944
2.9743397
-0.08987234
-1.6101289
-0.89792746
-4.028169
-5.377833
-6.4445467
-8.6214905
1.4907628
2.4756842
1.3024085
1.5153751
1.9540533
0.8280171
0.08810501
-0.108001694
-2.795832
-3.1643267
-1.8852804
0.7310804
0.7997393
-4.743191
-4.1702704
0.24465673
3.6964252
2.529699
-1.3813517
-6.483519
0.24939832
-4.157661
-0.64586824
1.9198651
1.4236256
1.3725876
-0.023328602
-4.4718723
-4.2961354
-0.7338463
-0.29752666
-0.06862523
2.0314543
2.4369051
-10.236425
-3.269651
1.1317075
3.0721195
0.71590775
1.1867813
5.2416673
-11.583184
4.348356
-1.6422191
-4.2318177
-1.8888206
-2.0061333
-1.52133
0.52539456
-2.3193445
-1.467778
-1.2235931
-1.5053993
-4.0289564
-1.9482174
6.241032
-1.6750438
1.0801417
1.1469369
1.3632966
2.0838962
2.760238
1.0222255
0.47412145
-11.695423
-10.03626
-2.3789573
3.5678174
2.374166
2.1371853
-1.5430331
-0.9649742
-0.93288946
-1.4996731
-1.2621634
1.7889644
8.54117
3.1049154
1.5017775
-1.7678075
0.39860016
2.0727968
-1.7361991
0.6959991
5.852141
-0.8183515
-1.7265427
-0.8796529
-3.298325
-3.2628438
2.1006303
0.9513111
1.4607509
0.005986915
1.2547166
-0.12963033
-5.6128345
8.270497
3.4684887
-3.4367008
-2.2029185
-0.52137333
3.4573855
-2.6177592
-11.774899
0.73199207
-5.085641
-3.1704664
-0.6501213
1.6413183
1.0107907
-1.8567976
0.63396835
2.3298132
3.1882627
2.3259728
1.4621435
2.7782733
5.313372
0.78562623
-0.0970473
2.7351143
2.2718618
3.8969364
-6.552176
-3.6910937
-2.1229317
-2.7929375
-1.0525937
-0.8904503
0.3890533
-0.72263604
-7.5203
-3.0688837
-1.7055917
-0.8072209
0.8379896
-2.3185794
2.5180013
3.9679234
3.233985
2.9243803
-0.223561
2.4954176
5.6240687
-1.8110671
0.5250148
2.0613344
2.8210561
1.3600023
1.9481804
0.41356388
0.64253575
2.3571844
1.8727428
-0.09483178
-0.10068758
-0.9865795
-2.0905862
-0.13578795
0.21638715
-5.2324834
-1.1332397
-0.16549379
-0.5591712
-4.693896
-5.4008656
-1.8201638
3.2251818
-2.472895
-0.98559844
-0.028081737
-0.3373084
-1.9851677
-3.9394991
-1.6555171
-2.210588
-1.5492698
-0.65099585
-4.200643
5.4318323
-2.0730338
-0.5083949
4.825373
2.3405094
6.0050144
7.621256
4.2057476
-7.2439837
0.3475756
-2.3020923
-0.9512121
-3.1858497
-0.54097694
1.0414405
1.6658882
2.7903888
0.9966476
1.7734951
0.7323225
-0.48802873
2.2202668
4.6883817
1.5694172
0.5084169
0.4579437
0.08427773
-0.84264606
-6.055248
3.8250737
4.3192205
-3.430983
-4.319295
-3.655368
-2.582509
-3.9624567
-3.9866087
1.0679773
-0.7509831
-0.87937534
-0.87057483
2.1272545
0.71704495
1.4701761
-1.9987628
-1.9698421
-0.46694785
3.7067578
3.0976222
-1.206871
0.67084455
1.5208381
-1.6203738
-0.8185926
0.81798756
1.4522221
2.4136586
1.87046
2.1499994
0.31972104
1.2351992
-0.48546556
-2.699795
4.1271415
-0.9770974
-0.6420178
2.3206024
0.35552558
0.019224508
-2.1218312
-3.7693448
-2.9461162
-5.087702
3.1475477
3.4898398
3.040477
0.3699896
0.13008937
-2.033924
-0.53392684
-1.2541277
-1.7381943
-2.044827
-1.5491427
0.93987614
-4.6978655
-4.1575365
-1.5324467
-2.267315
-3.0425246
-3.7083287
-2.7266552
10.546736
-7.138385
-1.0139745
0.027843866
-1.0776906
-3.3075335
-2.8957648
-2.2295258
-1.4765228
-2.2935975
-0.8915368
-2.3625367
1.2638682
0.46335712
6.7218175
0.22646861
-0.4110569
5.207876
2.661853
4.8026175
5.2316046
0.54989654
4.9117227
-0.40127888
0.92335147
0.8527189
-0.104409225
0.14774938
1.6824948
3.35685
1.4618059
1.4710565
1.0593895
-2.834192
3.4246871
-0.79423517
1.9520373
2.9527454
-1.5727447
-2.6508718
-4.6247873
-8.833994
-0.6045682
-6.1059384
-5.624346
-2.6234744
-0.65391165
4.723808
9.380394
11.877259
6.398099
-2.1160448
-1.4970033
-1.100544
-3.7545538
-4.5393553
3.0193498
-0.40089676
-2.5020967
2.1538439
-2.275054
-1.1674131
5.6752796
-9.289113
-5.1779776
1.761786
1.1194555
1.7774684
3.7627575
4.3141756
5.5247626
1.0698688
-1.2547325
-0.058076054
-1.0155064
-1.7294691
-0.26851955
-2.0001075
1.1471874
0.087851845
-2.4346879
-3.3749313
-5.223564
-2.6077735
-1.5271717
-7.7818465
-5.9920135
-4.7359343
-2.689116
0.7769361
1.9468406
0.8086373
2.7918034
4.8632493
4.9838977
5.6142254
-0.73577386
1.4218537
2.0464933
2.8875346
-0.29108846
-2.6644762
-1.9142792
-0.8027645
1.0292814
13.067977
1.7995297
-2.3520002
-1.5555915
2.6427572
4.129654
4.2482414
1.8631268
-2.9710379
-0.2672262
1.5440888
2.71317
1.437956
-4.1593404
-5.5961037
-1.625681
-3.2561655
-4.2879725
-3.5773783
-4.7864695
-0.73232985
8.950734
-5.698813
-1.9731523
0.30885452
-0.05687714
2.102644
2.16647
1.7816876
-2.0204372
-2.7761018
-2.724821
-2.7655087
-6.2742085
0.7061654
7.013888
3.5430462
-0.98313564
-1.4242945
0.1219717
2.9921522
-3.626394
-7.8853664
12.118143
1.7230028
3.13829
2.0216622
0.17564698
-2.3072734
-3.4869926
-0.6576443
-0.70670587
-0.6632217
0.10856182
3.2333748
1.2591472
-2.8783505
-5.832491
-0.35136712
2.7242649
1.1612006
-1.1837393
-1.2671982
-2.9786978
-3.3973956
5.2558517
4.0134277
-0.10333211
-2.3804312
-1.3334107
-3.4381874
2.2883117
3.094013
3.1400456
2.1522963
-5.689979
-4.6279507
-4.468437
-4.826356
-4.0788517
-5.395372
6.9401097
6.3601556
1.6255901
9.085926
6.7393723
2.7367263
1.8578042
-2.171023
-6.3990088
-4.3687057
-1.2057317
0.28539827
-3.9515052
-2.5466552
-2.3758597
0.9758952
-0.91801894
-3.7649019
1.4753187
-0.3567344
-1.4163746
-0.3364979
0.15975107
5.1324334
3.0642872
5.0193396
-5.2950196
-6.163257
-6.3299947
0.52889645
3.4331923
7.5148506
1.6006262
7.4639974
8.278794
7.7146654
5.108365
-1.1543223
-4.3407454
-7.416517
0.16366063
4.677001
6.0986156
2.1676981
-2.9215474
-15.661738
2.030821
1.46048
0.57291234
-0.48851165
-0.083110355
0.050475776
-1.5832611
-0.37080804
-1.7161357
-2.4429734
-3.2223065
-2.0982633
2.4830997
4.8509345
4.966224
3.7649117
1.6721911
1.027478
1.2670165
-1.2241313
-0.53053397
-1.5888321
-4.8202505
-3.7414117
0.032241177
-0.42953548
-1.082601
4.5059495
2.9944396
0.9001829
0.10427421
0.4272392
-1.0829779
-1.6061226
-4.2693267
-1.8416847
1.3545724
0.036020458
-3.7564528
-1.7609516
-0.80620885
-0.18423231
10.014584
2.268542
2.610936
-0.1622567
-2.839367
-2.0772088
2.9254804
3.5381086
0.21127546
-0.30353886
-0.95432526
-4.6826015
-3.7887986
3.79335
-1.7267298
-3.027444
-2.5614893
-1.8925852
-1.2459705
-5.829749
1.3447982
13.210692
1.2891082
0.20649998
-2.1504455
-6.887673
-5.3665185
-4.417357
0.49048346
6.821372
6.3965244
7.0950947
5.473547
7.9473763
-1.3468232
-6.323138
3.184112
0.41170022
-2.9893064
-2.3106396
2.9898713
4.5259347
10.934166
3.1015387
2.2009876
1.6763753
-0.82047546
1.8041412
4.098945
1.6822578
-1.993504
-2.8730888
-2.0779686
-2.7797084
3.2264464
-2.8019354
-3.761204
1.0395123
-3.9927819
-0.69344497
-3.3582678
-4.395657
-5.395441
-0.058109045
1.333843
0.9149747
0.28575614
-5.9736705
-5.89731
-4.3205576
1.4032481
1.0983771
0.9544648
0.1059671
-1.629145
0.72184616
0.8155513
-0.6943881
-0.19770963
4.8141227
-0.03228694
-0.60342276
-8.382484
-15.197585
4.4715366
2.2075837
2.2831562
0.2903444
0.9689209
-1.0517545
-2.4442356
0.3213583
4.1097093
5.446865
5.343674
0.67438734
-6.2766714
-1.5769013
-0.67598224
-1.3956145
-2.4217103
-5.4570475
-1.6408794
0.750944
-11.608931
-5.449131
-5.0826464
-3.3179965
-2.1141615
-1.4021862
-0.8141314
-3.692191
0.6133528
2.4623024
2.7781773
1.7517158
-1.4135972
0.5988687
5.3134203
-0.90052813
-1.3079045
-0.47876146
2.8974745
2.7497568
-2.7181516
6.931677
2.6527033
-10.392888
-9.958361
-5.5138745
-4.41187
-2.584785
4.770078
4.9908004
2.7973967
3.452585
3.496746
1.1161376
-0.26272988
-5.447661
1.0034784
0.8814963
-0.14432211
-2.249301
-3.3078873
-0.70347786
3.5413196
-3.9651244
-3.7389696
-5.672518
-3.4710736
-3.4314501
-3.312585
-1.1995839
0.8331398
-1.6202009
-1.535259
-0.9822233
-1.9127471
1.8404678
0.90115863
5.2356033
5.798692
2.457722
2.37555
1.9370898
3.886
-6.1013637
4.4613323
3.5757098
2.5174828
0.31211737
-3.589533
-2.5011396
0.6672078
2.2757
1.4286546
1.1707785
0.9696455
2.342216
-0.40811303
-1.1032075
-0.21875055
-0.15001932
3.9141393
-0.6466152
0.17659333
2.3178284
2.0070326
-1.7595148
-2.494626
-1.8073157
-2.175707
-0.7963677
0.8418734
6.74158
2.9064145
0.0022953954
0.23914027
-0.44117647
-1.3563472
-4.767541
0.12856784
-0.7229171
-1.0565622
-1.6430522
-2.343674
0.6362124
2.8047562
3.120332
0.65708786
0.66884667
-0.16430332
-0.16368961
-3.5627334
-1.9401232
-0.22015254
1.6301458
1.2996931
-0.9751892
-1.0888792
2.289594
-0.7287308
3.4397802
-1.7583598
-3.301323
3.2860973
3.1284218
4.7541394
2.7066202
0.59745604
1.2001992
-1.4319688
-1.6399975
-0.75900865
-3.889359
-2.9266284
-1.3498172
1.7399247
3.2172256
2.814731
3.4500234
4.8813114
5.246259
1.9997244
1.9173045
4.3841033
4.676194
3.8471324
0.90516865
-2.7072947
-3.6130047
-4.2313857
wgt 1 42 8
-4.929385
-12.0677805
2.0440722
6.3306875
-0.052459583
0.56575054
-2.2192144
-4.6507277
3.6278381
-1.5691413
9.886282
0.9841277
-1.7889946
-4.1738667
5.07377
-4.312193
-0.78240615
1.3075132
-4.908679
-0.9374228
3.1674798
-5.156057
-0.52604544
-7.7427497
3.378857
6.012011
5.3717017
-3.0699906
-3.742161
-1.8203006
0.0080578085
2.5943272
4.384225
-8.576328
0.59449846
3.852115
-7.8695483
-2.3711414
6.2802696
1.3074226
2.1549733
2.1926403
1.9103562
7.4493976
7.781855
-6.8641796
-0.663214
-3.2665675
2.6548223
-9.854533
1.647837
0.802091
1.166703
-0.8900605
3.4793696
0.62002397
-0.57750696
-1.1659374
-2.8248525
3.4989595
0.27418754
-3.2163234
0.52973413
3.256694
-3.4412708
-2.977407
-1.8851703
1.2174541
-0.5284839
1.878923
2.3557527
-8.793205
4.310578
-4.109945
0.45011067
-6.2518053
4.750428
0.26349717
-11.25744
3.5875
0.7831856
0.8639798
3.1073399
-3.3751855
-1.9091414
-0.022078652
4.074778
-3.9644141
0.1121411
-2.8190508
2.092944
0.2952176
1.8405942
-5.5219684
3.6559012
2.370945
-4.7816234
3.5774615
-7.339324
-4.2242737
-3.779107
0.3762528
0.3688975
1.511034
-0.79672503
0.22187369
2.6258247
6.3472676
-1.6818088
0.08174178
0.9092801
-0.22090966
3.0589411
0.22791092
4.941212
-1.7747015
-3.321135
5.586107
-1.0043377
-5.3023734
-9.592163
3.4226253
2.9096375
2.288854
0.13283148
0.09227249
-1.1809939
17.304705
11.207538
-3.7153149
-0.5841589
-8.543778
-2.9898682
-4.1993637
-3.5652092
3.7063122
6.212659
1.5706457
-0.16208303
-1.0504726
-0.28515455
2.983466
-6.4450126
0.21874909
-1.01034
1.7784203
-1.7146593
-7.432414
-3.7362714
11.553775
-0.83870965
2.2612734
0.6336078
-2.2163212
-3.7113507
8.37739
9.092728
-4.477766
3.3103454
-8.248878
3.194602
4.665069
4.1781178
-1.1049556
1.0778539
2.4139805
-0.13841398
3.805322
-1.761507
-1.0848331
-1.1846548
0.5272013
-2.6701524
0.8803219
4.249613
-4.588745
3.6552947
0.19351587
3.8183398
-1.4226022
-2.0200543
-3.6722195
-5.776708
3.1387782
4.2544394
-1.6456953
-2.910292
4.197794
-5.285994
-1.1655107
-1.4606986
-1.4199052
3.8052716
1.1253309
-0.6346062
7.2952886
-4.2459936
-5.0116057
-7.0158167
3.776426
4.056642
13.95454
-4.571903
-0.17473571
-10.686482
6.9032936
-4.841524
3.5662088
-0.97569555
2.0801418
-1.469348
9.998016
-0.9172923
5.2916903
-4.0285916
2.6602635
0.38555008
1.3548276
-3.4938936
-3.0317645
-7.473786
0.9492468
0.41389957
-1.8095533
-5.0790453
1.2885945
4.9310436
0.92794114
9.214784
-1.7541118
-2.6382854
0.24626029
-3.7976437
-1.3126866
4.4930673
-0.36584952
5.3223276
-2.4668415
0.88712806
1.0481945
-2.1997285
-1.6928488
-3.320491
6.207278
-10.1042385
-1.5388055
12.393207
0.5728246
4.501737
-0.37854612
1.3395416
1.6798944
-1.356297
-7.640693
-8.495915
-7.9349566
-0.8321368
0.4284385
-1.2142506
0.42124572
-0.473485
0.04801537
-1.9944115
3.997104
0.38437474
2.620607
-4.6454496
-0.4660952
-0.70594805
2.4773054
-0.48868057
0.54459167
-3.464262
-1.5059245
9.029734
-7.5053806
4.2247057
-4.227704
3.5963922
2.0522683
-0.8435147
-1.4315345
-0.6442299
-0.5237667
-0.8667609
12.211018
-0.63485456
-0.64892024
1.0273236
2.1290293
-0.83797294
-3.5701559
-0.23258252
2.7489436
-0.85350394
-17.02423
-14.35848
8.882097
0.15538834
-0.9279382
-2.683057
-3.2712646
-10.482704
-5.4637303
1.6440675
-1.1216397
-1.5138923
4.2122746
15.462642
8.980506
7.0207844
0.42790577
2.5942206
2.5512993
-4.5740604
0.98590845
-9.173388
2.462372
2.0172336
-1.3914394
1.165924
-0.3202403
0.453431
-2.5022838
-2.2389843
1.748616
-2.8359485
-28.460905
-4.7789907
0.8340804
-27.944956
0.51175696
0.94220686
0.41869155
0.85689276
0.66286635
wgt 2 8 4
-0.14806154
1.7521132
-7.4277034
-2.3668745
6.384902
-5.293011
5.528414
-8.553271
-5.754518
-1.5011181
-3.769856
-24.990665
4.2646155
-0.07470964
-5.3483176
12.814197
0.16039117
-4.0571575
2.154725
-2.280804
-1.4236375
-6.465168
7.1997867
-5.567611
-0.3249898
4.2569256
-0.73578894
-2.979954
-2.4814756
-9.158995
-7.3214417
4.276728
wgt 3 4 2
4.5814815
-18.923227
5.3284516
-10.752006
-9.457872
-9.166318
15.8451605
3.6174746
wgt 4 2 1
7.2688136
5.2316823
```
